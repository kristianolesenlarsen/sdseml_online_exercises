{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - linear ML for econometrics. \n",
    "\n",
    "In this exercise set we will work with linear ML methods that can give unbiased estimates when the number of covariates is large. We will once again set up simulated data to clearly see any issues with the methods we apply. The exercises follow the approach laid out in [Chernozhukov et al](https://arxiv.org/pdf/1501.03185.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "adder() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-7dab5aa99beb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0madd_number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0madder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: adder() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "# \"quick\" warm up\n",
    "\n",
    "def adder():\n",
    "    add_number = np.sum()\n",
    "    return add_number\n",
    "\n",
    "adder(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following code simulates two datasets, one to use with the auxilliary regression \n",
    ">$$ \\tag{aux}\n",
    "d_i = x_i'\\gamma_0 + z_i' \\delta_0 + u_i\n",
    "$$\n",
    ">and one to use in the main equation\n",
    ">$$ \\tag{main}\n",
    "y_i = \\alpha_0 d_i + x_i' \\beta_0 + \\nu_i\n",
    "$$\n",
    "Unlike in the paper, we include covariates in the main equation. We will handle them in a later question. In this setup $u_i$ and $\\nu_i$ are correlated, meaning the relation between $d_i$ and $y_i$ is not identified via OLS. Instead we will use $z_i$ to induce exogenous variation in $d_i$, which is unrelated to the error terms. This variation can be used to identify $\\alpha_0$.\n",
    ">\n",
    "> **Ex 6.1.1.**  Rewrite the below code to define a function `simulate(n, m, k, plot)`, where plot is a boolean indicating whether the density plot should be drawn or not. Your function should return all the matrices and vectors required in the regression equations, including parameters and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.78905067 -3.78905067]\n",
      " [-1.20339789 -1.2033979 ]\n",
      " [-1.99636773 -1.99636773]\n",
      " ...\n",
      " [-1.1286134  -1.12861341]\n",
      " [ 4.86549008  4.86549008]\n",
      " [ 0.01077665  0.01077667]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1000  # Number of observations\n",
    "m = 1500    # Number of potential instruments\n",
    "k = 10    # Number of covariates\n",
    "\n",
    "cov = 5\n",
    "errors = np.random.multivariate_normal(mean = [0,0], cov = [[cov, cov], [cov, cov]], size = n)\n",
    "h = sns.jointplot(errors[:,0], errors[:,1], kind = 'kde')\n",
    "h.set_axis_labels('$\\\\nu$', '$\\epsilon$', fontsize=16)\n",
    "\n",
    "z = np.random.normal(size = (n,m))\n",
    "x = np.random.normal(size = (n,k))\n",
    "\n",
    "# Auxilliary equation\n",
    "nu = errors[:,0]\n",
    "Pi = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = m - 1)])\n",
    "gamma = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "\n",
    "d = z @ Pi + x @ gamma + nu\n",
    "\n",
    "# Main equation\n",
    "u = errors[:,1]\n",
    "delta = np.array([5] + [x  if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "alpha = np.random.uniform(1,2)\n",
    "\n",
    "y = alpha * d  + x @ delta + u\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(n, m, k, plot = False):\n",
    "\n",
    "    n = 1000  # Number of observations\n",
    "    m = 1500    # Number of potential instruments\n",
    "    k = 10    # Number of covariates\n",
    "\n",
    "    cov = 5\n",
    "\n",
    "    errors = np.random.multivariate_normal(mean = [0,0], cov = [[cov, cov], [cov, cov]], size = n)\n",
    "    if plot == True:\n",
    "        h = sns.jointplot(errors[:,0], errors[:,1], kind = 'kde')\n",
    "        h.set_axis_labels('$\\\\nu$', '$\\epsilon$', fontsize=16)\n",
    "\n",
    "    z = np.random.normal(size = (n,m))\n",
    "    x = np.random.normal(size = (n,k))\n",
    "\n",
    "    # Auxilliary equation \n",
    "    nu = errors[:,0]\n",
    "    Pi = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = m - 1)])\n",
    "    gamma = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "\n",
    "    d = z @ Pi + x @ gamma + nu\n",
    "\n",
    "    # Main equation\n",
    "    u = errors[:,1]\n",
    "    delta = np.array([5] + [x  if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "    alpha = np.random.uniform(1,2)\n",
    "\n",
    "    y = alpha * d  + x @ delta + u\n",
    "    \n",
    "\n",
    "\n",
    "    return((d, z, Pi, x, gamma, nu),(y, alpha , x, delta, u))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.2:** Use your function to simulate a new dataset and regress the following OLS regression\n",
    ">$$\n",
    "y_i \\sim \\pi_0 + \\pi_1 d_i + \\gamma_i\n",
    "$$\n",
    "> where $\\gamma_i$ is a noise term. \n",
    ">\n",
    "> Repeat this procedure 1000 times in a for loop and store the true $\\alpha_0$ as well as the estimate $\\pi_1$ in two lists. Plot a histogram of the differences $\\alpha_0 - \\pi_1$. What does this tell you about the regression you just ran?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS\n",
    "from statsmodels.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.          0.          0.          0.          0.         -0.69519798\n",
      "  0.          0.          0.          0.        ]\n",
      "1.7546463139970592\n"
     ]
    }
   ],
   "source": [
    "A = []\n",
    "B = []  \n",
    "\n",
    "#running the simulation 1000 times\n",
    "\n",
    "for i in range(5):\n",
    "    auxilliary, main = simulate(n, m, k, plot= False)\n",
    "    d, z, Pi, x, gamma, nu = auxilliary #unpacking variables for aux regression\n",
    "    y, x, delta, alpha, u = main # unpacking variable for main equation\n",
    "    \n",
    "# Estimating parameter pi1 with ols \n",
    "\n",
    "    model = OLS(y, add_constant(d))\n",
    "    fitted_model= model.fit()\n",
    "    \n",
    "    # create lists of true- and estimated values; A and B\n",
    "\n",
    "    A.append(alpha)\n",
    "    B.append(fitted_model.params[1])\n",
    "\n",
    "# Hey Kristian, jeg sidder fast her. Når jeg laver en liste med det faktiske alhpa-værdier, er der\n",
    "# 10 værdier for hvert alpha, som ofte (men ikke altid) har udseende [5 0 0 0 0 0 0 0 0 0].\n",
    "# Jeg synes kun der skal være én for hver simulation, eller er jeg gal på den?\n",
    "# lige meget hvad bliver det underligt, når jeg skal plotte, fordi der er lige så mange fordelinger, som der er simulationer\n",
    "# jeg har kun kørt 5 simuleringer, så kører koden lidt hurtigere. \n",
    "\n",
    "# Den er god nok for hver af de estimerede ols-parametere, derfår jeg ét estimat for hver simulation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.3:** Knowing the DGP an obvious solution would be to run an IV regression, instrumenting $d_i$ with $z_i$. Unfortunately there are $m=1500$ columns in $z_i$ and only $n=1000$ observations. Luckily, the way we have simulated our data only a small subset of the $z_i$'s actually influence $d_i$. The tricky part will be to pick out the right $z_i$'s.\n",
    ">\n",
    "> To begin with simulate a new dataset and count the number of non-zero element in $\\Pi$ to verify that indeed only very few $z$'s matter for $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 150 nonzeros\n"
     ]
    }
   ],
   "source": [
    "auxilliary, main = simulate(n, m, k, plot= False)\n",
    "d, z, Pi, x, gamma, nu = auxilliary #unpacking variables for aux regression\n",
    "y, x, delta, alpha, u = main # unpacking variable for main equation\n",
    "\n",
    "# counting the amount of nonzeros in Pi\n",
    "print(\"there are\", np.count_nonzero(Pi),\"nonzeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.4:** The _ideal_ instrument for $d_i$ is exactly the $z_i$'s which have non-zero coefficients, multiplies by the corresponding true simulated parameters in $\\delta_0$. Having simulated the data ourselves, an easy way to compute this is to simply calculate\n",
    "> $$\n",
    "\\hat{d}^* = z \\cdot \\delta_0\n",
    "$$\n",
    "> where $\\cdot$ is the dot product, written as `@` in numpy. In reality we cannot get this ideal instrument, because it would require regressing $d_i$ on all 500 variables with only 100 observations.  \n",
    ">\n",
    "> In a for loop over 1000 iterations, simulate new data, compute the ideal instrument $\\hat{d_i}$ and regress the second stage regression $y_i \\sim \\pi_0 + \\pi_1\\hat{d_i}$. Store the true $\\alpha_0$ and the estimate $\\hat{\\pi}_1$ in two lists. Finally draw a histogram of the differences $\\alpha_0 - \\hat{\\pi}_1$. How does your histogram look this time, is this expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([5, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([5, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([5, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([ 5.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -1.95602112,  0.        ,  0.        ,  0.        ,  0.        ]), array([ 5.        ,  0.        ,  0.        , -1.91264346,  0.        ,\n",
      "        3.60749253,  0.55785452,  0.        ,  0.        ,  0.        ])]\n"
     ]
    }
   ],
   "source": [
    "# for loop to run a certain amount of simulations\n",
    "\n",
    "C = []\n",
    "D = []\n",
    "\n",
    "for i in range(5):\n",
    "    auxilliary, main = simulate(n, m, k, plot= False)\n",
    "    d, z, Pi, x, gamma, nu = auxilliary #unpacking variables for aux regression\n",
    "    y, x, delta, alpha, u = main # unpacking variable for main equation\n",
    "\n",
    "    d_hat = z @ Pi\n",
    "    \n",
    "    IV_model = OLS(y, add_constant(d_hat))\n",
    "    fitted_model = IV_model.fit()\n",
    "    \n",
    "    C.append(alpha)\n",
    "    D.append(fitted_model.params[1])\n",
    "\n",
    "# Her rammer ind i samme problem som i 6.1.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.5:** The below class implements post-lasso. A two step procedure where first a lasso model is used to identify relevant parameters, and then OLS is used to estimate parameter values on the remaining variables. Study the code, and understand as well as possible what is going on. \n",
    ">\n",
    "> What is stored in `relevant_x`?\n",
    "> \n",
    "> Why is the `predict` method so complicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostLasso:\n",
    "    def __init__(self, formula = None):\n",
    "        self.lasso_model = Lasso()\n",
    "        self.ols_model = None\n",
    "        self.relevant_x = None\n",
    "        self.subset_cols = None\n",
    "        self.coefs = None\n",
    "        self.formula = formula\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'PostLasso({self.formula})'\n",
    "    \n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, X, y, force_include_idx = None):\n",
    "        ''' Estimate a model using Post-Lasso\n",
    "        \n",
    "        X: X matrix (without intercept)\n",
    "        y: y vector\n",
    "        force_include_idx: column indexes that ALWAYS is\n",
    "            included in the OLS model, regardless of their\n",
    "            status in the lasso stage.\n",
    "        '''\n",
    "        self.lasso_model = self.lasso_model.fit(X,y)\n",
    "        self.coefs = np.insert(self.lasso_model.coef_, 0, self.lasso_model.intercept_)\n",
    "        self.subset_cols = np.where(self.coefs != 0)[0]\n",
    "        if force_include_idx is not None:\n",
    "            self.subset_cols = np.union1d(self.subset_cols, force_include_idx)\n",
    "        self.relevant_x = add_constant(X)[:,self.subset_cols]\n",
    "        self.ols_model = OLS(y, self.relevant_x).fit()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X = None):\n",
    "        ''' Predict using a fitted post-lasso model.\n",
    "        '''\n",
    "        if X is None:\n",
    "            return self.ols_model.predict(self.relevant_x)\n",
    "        if X.shape == self.relevant_x.shape:\n",
    "            return self.ols_model.predict(X)\n",
    "        return self.ols_model.predict(X[:,self.subset_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.6:** In this problem we will try to run through the post-lasso steps required to obtain an estimate of $\\alpha_0$. Since we are doing this in python we will not be able to set the lasso hyperparameter optimally for this kind of post-selection usage. There is a R package, developed especially to handle inference after lasso-selection, which you should use in practise. \n",
    ">\n",
    "> For now, do the following steps 1000 times, storing the true $\\alpha_0$ and estimate $\\hat{\\alpha_0}$:\n",
    ">\n",
    "> * 0. Simulate a new dataset.\n",
    "> * 1. Run a post-lasso regression of d on x and z, $d_i \\sim x_i'\\gamma + z_i' \\delta$, forcing the inclusion of $x_i$ in the OLS stage.\n",
    "> * 2. Run the second stage regression $y_i \\sim \\hat{d}_i + x_i' \\beta$ to recover $\\hat{\\alpha_0}$.\n",
    ">\n",
    "> How does this histogram compare to the naive one? How does it compare to the ideal one?\n",
    ">\n",
    "> _Hint:_ We follow the description given on page 19 [here](https://cran.r-project.org/web/packages/hdm/vignettes/hdm.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Your solution here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}